{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According the descriptions in CIFAR-10 official website(http://www.cs.toronto.edu/~kriz/cifar.html), the CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "\n",
    "Five training batches, 5 * 10000 images\n",
    "=> 10 classes * 5000 images/class\n",
    "\n",
    "One test batch, each with 1000 images. \n",
    "=> 10 classes * 1000 images/class\n",
    "\n",
    "I will use binary version for example:\n",
    "\n",
    "The binary version contains the files data_batch_1.bin, data_batch_2.bin, ..., data_batch_5.bin, as well as test_batch.bin. Each of these files is formatted as follows: \n",
    "    \n",
    "    <1 x label><3072 x pixel>\n",
    "    ...\n",
    "    <1 x label><3072 x pixel>\n",
    "\n",
    "The first byte is label, followed RGB data 32 * 32 * 3 = 3072 bytes. \n",
    "\n",
    "Each file contains 10000 such 3073-byte \"rows\" of images, although there is nothing delimiting the rows. Therefore each file should be exactly 30730000 bytes long. \n",
    "\n",
    "Now I will do some explanation about tensorflow CIFAR-10 official code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. read cifar-10 data\n",
    "\n",
    "\n",
    "<img src=\"file_reader_machenism.png\" width=\"70%\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prefer old data-reading code as it will show us the details of data processing.\n",
    "\n",
    "=> Step 1: create filename queue using  tf.train.string_input_producer()\n",
    "    \n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d.bin' % i)\n",
    "               for i in xrange(1, 6)]\n",
    "    filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "=> Step 2: reader.read(reader = tf.FixedLengthRecorder() to get fixed length data) to get the data from the filename queue.\n",
    "    (key step: combined reader.read with filename queue)\n",
    "    \n",
    "    label_bytes = 1  # 2 for CIFAR-100\n",
    "    result.height = 32\n",
    "    result.width = 32\n",
    "    result.depth = 3\n",
    "    image_bytes = result.height * result.width * result.depth\n",
    "    # Every record consists of a label followed by the image, with a # fixed number of bytes for each.\n",
    "  \n",
    "    record_bytes = label_bytes + image_bytes\n",
    "\n",
    "    # Read a record, getting filenames from the filename_queue.  No\n",
    "    # header or footer in the CIFAR-10 format, so we leave header_bytes\n",
    "    # and footer_bytes at their default of 0.\n",
    "               \n",
    "    reader = tf.FixedLengthRecordReader(record_bytes=record_bytes)\n",
    "    result.key, value = reader.read(filename_queue)\n",
    "\n",
    "    # Convert from a string to a vector of uint8 that is record_bytes long.\n",
    "  \n",
    "    record_bytes = tf.decode_raw(value, tf.uint8)\n",
    "\n",
    "=> Step 3: reshape the original figure.\n",
    "\n",
    "    # Image processing for training the network. Note the many random\n",
    "    # distortions applied to the image.\n",
    "\n",
    "    # Randomly crop a [height, width] section of the image.\n",
    "  \n",
    "    distorted_image = tf.random_crop(reshaped_image, [height, width, 3])\n",
    "\n",
    "    # Randomly flip the image horizontally.\n",
    "    \n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "\n",
    "    # Because these operations are not commutative, consider randomizing\n",
    "    # the order their operation.\n",
    "  \n",
    "    distorted_image = tf.image.random_brightness(distorted_image,\n",
    "                                               max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(distorted_image,\n",
    "                                             lower=0.2, upper=1.8)\n",
    "\n",
    "    # Subtract off the mean and divide by the variance of the pixels.\n",
    "    \n",
    "    float_image = tf.image.per_image_standardization(distorted_image)\n",
    "\n",
    "    # Set the shapes of tensors.\n",
    "  \n",
    "    float_image.set_shape([height, width, 3])\n",
    "    read_input.label.set_shape([1])\n",
    "=> step 4: form a batch of images and labels for training.\n",
    "    \n",
    "    images, label_batch = tf.train.shuffle_batch(\n",
    "        [image, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=num_preprocess_threads,\n",
    "        capacity=min_queue_examples + 3 * batch_size,\n",
    "        min_after_dequeue=min_queue_examples)\n",
    "\n",
    "\n",
    "Questions: 1. tf.train.string_input_producer(), I cannot see tf.train.start_queue_runners()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. CNN model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> convolution 1 (64 filter with shape [5, 5, 3])\n",
    "        \n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[5, 5, 3, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    _activation_summary(conv1)\n",
    "\n",
    "=> convolution 2 (64 filter with shape [5, 5, 64])\n",
    "\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[5, 5, 64, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=0.0)\n",
    "    conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    _activation_summary(conv2)\n",
    "\n",
    "\n",
    "=> two full connection layer\n",
    "\n",
    "    with tf.variable_scope('local3') as scope:\n",
    "    # Move everything into depth so we can perform a single matrix multiply.\n",
    "    reshape = tf.reshape(pool2, [FLAGS.batch_size, -1])\n",
    "    dim = reshape.get_shape()[1].value\n",
    "    weights = _variable_with_weight_decay('weights', shape=[dim, 384],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))\n",
    "    local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "    _activation_summary(local3)\n",
    "\n",
    "\n",
    "    with tf.variable_scope('local4') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', shape=[384, 192],\n",
    "                                          stddev=0.04, wd=0.004)\n",
    "    biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))\n",
    "    local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
    "    _activation_summary(local4)\n",
    "\n",
    "=> softmax layer\n",
    "      \n",
    "    with tf.variable_scope('softmax_linear') as scope:\n",
    "    weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],\n",
    "                                          stddev=1/192.0, wd=0.0)\n",
    "    biases = _variable_on_cpu('biases', [NUM_CLASSES],\n",
    "                              tf.constant_initializer(0.0))\n",
    "    softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "    _activation_summary(softmax_linear)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. loss (use cross entropy as default) \n",
    "\n",
    "   labels = tf.cast(labels, tf.int64)\n",
    "   cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "      labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "   cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. train\n",
    "\n",
    "=> update learning rate\n",
    "\n",
    "    //# Variables that affect learning rate.\n",
    "    num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size # (50000 / 128)\n",
    "    decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)             # per 350 batchs update learning rate once\n",
    "\n",
    "    //# Decay the learning rate exponentially based on the number of steps.\n",
    "    lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
    "                                  global_step,\n",
    "                                  decay_steps,\n",
    "                                  LEARNING_RATE_DECAY_FACTOR,\n",
    "                                  staircase=True)\n",
    "    tf.summary.scalar('learning_rate', lr)\n",
    "    \n",
    "=>  calcualte gradients\n",
    "\n",
    "    # Compute gradients.\n",
    "    with tf.control_dependencies([loss_averages_op]):\n",
    "    opt = tf.train.GradientDescentOptimizer(lr)\n",
    "    grads = opt.compute_gradients(total_loss)\n",
    "\n",
    "    # Apply gradients.\n",
    "    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "    # Add histograms for trainable variables.\n",
    "    for var in tf.trainable_variables():\n",
    "    tf.summary.histogram(var.op.name, var)\n",
    "\n",
    "    # Add histograms for gradients.\n",
    "    for grad, var in grads:\n",
    "      if grad is not None:\n",
    "        tf.summary.histogram(var.op.name + '/gradients', grad)\n",
    "\n",
    "    # Track the moving averages of all trainable variables.\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(\n",
    "      MOVING_AVERAGE_DECAY, global_step)\n",
    "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "    with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n",
    "        train_op = tf.no_op(name='train') # do noting, but wait for apply_gradient_op, variables_averages_op being finished.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. start session\n",
    "\n",
    "         class _LoggerHook(tf.train.SessionRunHook):\n",
    "              \"\"\"Logs loss and runtime.\"\"\"\n",
    "\n",
    "              def begin(self):\n",
    "                self._step = -1\n",
    "                self._start_time = time.time()\n",
    "\n",
    "              def before_run(self, run_context):\n",
    "                self._step += 1\n",
    "                return tf.train.SessionRunArgs(loss)  # Asks for loss value.\n",
    "\n",
    "              def after_run(self, run_context, run_values):\n",
    "                if self._step % FLAGS.log_frequency == 0:\n",
    "                  current_time = time.time()\n",
    "                  duration = current_time - self._start_time\n",
    "                  self._start_time = current_time\n",
    "\n",
    "                  loss_value = run_values.results // that is tf.train.SessionRunArgs(loss)\n",
    "                  examples_per_sec = FLAGS.log_frequency * FLAGS.batch_size / duration\n",
    "                  sec_per_batch = float(duration / FLAGS.log_frequency)\n",
    "\n",
    "                  format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                                'sec/batch)')\n",
    "                  print(format_str % (datetime.now(), self._step, loss_value,\n",
    "                                      examples_per_sec, sec_per_batch))\n",
    "\n",
    "            with tf.train.MonitoredTrainingSession(\n",
    "                checkpoint_dir=FLAGS.train_dir,\n",
    "                hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),\n",
    "                       tf.train.NanTensorHook(loss),\n",
    "                       _LoggerHook()],\n",
    "                config=tf.ConfigProto(\n",
    "                    log_device_placement=FLAGS.log_device_placement)) as mon_sess: # whether to print cpu affinity log\n",
    "             # set last_step to FLAGS.max_steps, and stop until reached the max steps\n",
    "             while not mon_sess.should_stop():\n",
    "                mon_sess.run(train_op)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Evaluation \n",
    "\n",
    "=> get images and labels\n",
    "\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    eval_data = FLAGS.eval_data == 'test'\n",
    "    images, labels = cifar10.inputs(eval_data=eval_data)\n",
    "\n",
    "=> build cnn model\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    logits = cifar10.inference(images)\n",
    "\n",
    "=> Calculate prediction.\n",
    "\n",
    "    top_k_op = tf.nn.in_top_k(logits, labels, 1)\n",
    "\n",
    "    # tf.nn.in_top_k(predictions, targets, k, name=None)\n",
    "    # A = [[0.8,0.6,0.3], [0.1,0.6,0.4]]\n",
    "    # B = [1, 1]\n",
    "    # out = tf.nn.in_top_k(A, B, 1)\n",
    "    # top 1 in A[0] is A[0]max = 0.8, idx = 0\n",
    "    # top 1 in A[1] is A[1]max = 0.6, idx = 1\n",
    "    # so out is [false true]\n",
    "    \n",
    "=>  Every FLAGS.eval_interval_secs seconds, it will evaluation once. For each evaluation, it will record a precision.\n",
    "\n",
    "    # Start the queue runners.\n",
    "    coord = tf.train.Coordinator()\n",
    "    try:\n",
    "      threads = []\n",
    "      for qr in tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS):\n",
    "        threads.extend(qr.create_threads(sess, coord=coord, daemon=True,\n",
    "                                         start=True))\n",
    "\n",
    "      num_iter = int(math.ceil(FLAGS.num_examples / FLAGS.batch_size))\n",
    "      true_count = 0  # Counts the number of correct predictions.\n",
    "      total_sample_count = num_iter * FLAGS.batch_size\n",
    "      step = 0\n",
    "      while step < num_iter and not coord.should_stop():\n",
    "        predictions = sess.run([top_k_op])\n",
    "        true_count += np.sum(predictions)\n",
    "        step += 1\n",
    "\n",
    "      # Compute precision @ 1.\n",
    "      precision = true_count / total_sample_count\n",
    "      print('%s: precision @ 1 = %.3f' % (datetime.now(), precision))\n",
    "\n",
    "     summary = tf.Summary()\n",
    "      summary.ParseFromString(sess.run(summary_op))\n",
    "      summary.value.add(tag='Precision @ 1', simple_value=precision)\n",
    "      summary_writer.add_summary(summary, global_step)\n",
    "    except Exception as e:  # pylint: disable=broad-except\n",
    "      coord.request_stop(e)\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads, stop_grace_period_secs=10)\n",
    "\n",
    "\n",
    "Notes: Need some time to dig usages of tf queues, threads.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
